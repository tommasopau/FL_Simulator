import torch
import logging
from utils.seeding import set_deterministic_mode
from utils.logger import setup_logger
setup_logger() 
from pydantic import ValidationError
from utils.models import MNISTCNN, FCMNIST , ZalandoCNN , FNet
from utils.constants import ALLOWED_FILTERS
from dataset import FederatedDataLoader, DatasetHandler , server_dataset
from server import Server, AggregationStrategy, AttackServer, AttackType , FLTrust
import multiprocessing
import ray
from flask import Flask, jsonify, request
from utils.config import Config, load_config , serialize_config , validate_config
from utils.db import get_engine, create_tables, get_session, SimulationResult
from sqlalchemy import and_, or_, Boolean , inspect
import json


def main():
    # Initialize Ray
    ray.init()
    try:
        
        
        # Initialize centralized logger
            
        logger = logging.getLogger(__name__)
        logger.info("Main process started.")
            
        config = load_config('config.yaml')
        config = config.model_dump()

        validate_config(config)
            
        federated_cfg = config['federated_learning']
        model_cfg = config['model']
            
        set_deterministic_mode(federated_cfg.get('seed', 42))
            
        # Verify device availability
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        logger.info(f"Using device: {device}")
            
        # Model selection based on config
        model_mapping = {
                'MNISTCNN': MNISTCNN,
                'FCMNIST': FCMNIST,
                'ZalandoCNN' : ZalandoCNN ,
                'FNet' : FNet
        }
        model_type = model_cfg.get('type', 'FCMNIST')
        model_class = model_mapping.get(model_type)
        if model_class is None:
            logger.error(f"Unsupported model type: {model_type}")
            raise ValueError(f"Unsupported model type: {model_type}")
            
        global_model = model_class().to(device)
        logger.info(f"Initialized global model: {model_type}")
            
        # Initialize DatasetHandler
        federated_dataset_handler = DatasetHandler(
        datasetID=federated_cfg['dataset'],
        num_clients=federated_cfg['num_clients'],
        partition_type=federated_cfg['partition_type'],
        alpha=federated_cfg['alpha'],
        seed=federated_cfg.get('seed', 42),
        )
        if federated_cfg['attack'].upper() == 'LABEL_FLIP':
            federated_dataset_handler.label_flipping_attack = True
            federated_dataset_handler.num_attackers = federated_cfg['num_attackers']
        federated_dataset_handler._initialize_partitioner()
        federated_dataset_handler.load_federated_dataset()    
        # Initialize FederatedDataLoader
        federated_data_loader = FederatedDataLoader(
            dataset_handler=federated_dataset_handler,
            batch_size=federated_cfg['batch_size'],
            device=device
        )
        
        
            
        attack_str = federated_cfg.get('attack', None)
            
        attack_type = AttackType[attack_str.upper()]
        
        if federated_cfg['aggregation_strategy'].upper() == 'FLTRUST':
            server_data_loader = server_dataset(federated_cfg['dataset'], federated_cfg['batch_size'], device)
            # Instantiate FLTrust server.
            server = FLTrust(
                server_data_loader=server_data_loader,
                attack_type=attack_type,
                federated_data_loader=federated_data_loader,
                global_model=global_model,
                aggregation_strategy=AggregationStrategy.FLTRUST,
                sampled=federated_cfg['sampled_clients'],
                global_epochs=federated_cfg['global_epochs'],
                local_epochs=federated_cfg['local_epochs'],
                learning_rate=federated_cfg['learning_rate'],
                batch_size=federated_cfg['batch_size'],
                local_dp=federated_cfg['local_DP_SGD'],
                device=device,
                f=federated_cfg['num_attackers'],
            )
        else:
            aggregation_strategy = federated_cfg.get('aggregation_strategy')
            aggregation_strategy = AggregationStrategy[aggregation_strategy]
            server = AttackServer(
                attack_type=attack_type,
                federated_data_loader=federated_data_loader,
                global_model=global_model,
                aggregation_strategy=aggregation_strategy,
                sampled = federated_cfg['sampled_clients'],
                global_epochs=federated_cfg['global_epochs'],
                local_epochs=federated_cfg['local_epochs'],
                learning_rate=federated_cfg['learning_rate'],
                batch_size=federated_cfg['batch_size'],
                local_dp = federated_cfg['local_DP_SGD'],
                device=device,
                f = federated_cfg['num_attackers'],
                    
            )

        # Run federated training and emit updates
        accuracy = server.run_federated_training()
        try:
            result_filepath = "results.txt"  # change to absolute path if needed
            with open(result_filepath, "a") as result_file:
                result_file.write("Simulation Result\n")
                result_file.write(f"Accuracy: {accuracy}\n")
                result_file.write("Configuration:\n")
                result_file.write(json.dumps(config, indent=4))
            logger.info(f"Results saved to {result_filepath}")
        except Exception as write_exc:
            logger.error(f"Failed to write simulation results to file: {write_exc}")
    except Exception as e:
        logger.error(f"Error during federated learning: {e}")
    finally:
        ray.shutdown()
            

if __name__ == '__main__':
    main()